{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Neural Network (CNN) for Image Classification**\n",
    "\n",
    "Packages for dealing with images:\n",
    "1. [OpenCV](https://pypi.org/project/opencv-python/)\n",
    "2. [Matplotlib](https://matplotlib.org/)\n",
    "3. [Pillow](https://pillow.readthedocs.io/en/stable/)\n",
    "3. [scikit-image](https://scikit-image.org/)\n",
    "4. [Tensorflow](https://www.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Unterverzeichnisse: 5\n",
      "Shape of images array: (250, 384, 512, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 250 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_filenames(filepath):\n",
    "    # Lade alle .jpg-Dateien rekursiv aus dem Verzeichnis und seinen Unterordnern\n",
    "    imagefiles = [f for f in glob.glob(filepath + '/**/*.jpg', recursive=True)]  # '**/' f√ºr rekursive Suche\n",
    "    return imagefiles \n",
    "\n",
    "def read_images(filenames, height=None, width=None):\n",
    "    images = [Image.open(filename) for filename in filenames]\n",
    "    if (not height is None) and (not width is None):\n",
    "        images = [img.resize((width, height)) for img in images]\n",
    "    return images\n",
    "\n",
    "def images_to_array(images):\n",
    "    return np.asarray([np.asarray(img) for img in images])\n",
    "\n",
    "path = r'C:\\Users\\Thore\\Desktop\\KI\\ki\\Garbage classification'\n",
    "num_dirs = sum(os.path.isdir(os.path.join(path, i)) for i in os.listdir(path))\n",
    "print(f\"Anzahl der Unterverzeichnisse: {num_dirs}\")\n",
    "\n",
    "# Get file names\n",
    "image_names = get_filenames(path)\n",
    "\n",
    "# Load images\n",
    "input_shape = {\n",
    "    \"height\": 384,\n",
    "    \"width\": 512,\n",
    "    \"channels\": 3\n",
    "}\n",
    "images = read_images(image_names, height=input_shape[\"height\"], width=input_shape[\"width\"])\n",
    "\n",
    "# Convert images to array\n",
    "aimages = images_to_array(images)\n",
    "print(f'Shape of images array: {aimages.shape}')\n",
    "\n",
    "# Plot images array\n",
    "#display(Image.fromarray(aimages[11]))\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "rows, columns = num_dirs, 50\n",
    "for i in range(aimages.shape[0]):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(aimages[i, ...])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'cardboard', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'glass', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'metal', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'paper', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic', 'plastic']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label list\n",
    "def flatten_lst(lst):\n",
    "    return [item for items in lst for item in items]\n",
    "\n",
    "# def get_folder_names(filepath):\n",
    "#     # Holen der Namen aller Ordner im angegebenen Verzeichnis\n",
    "#     folder_names = [folder for folder in os.listdir(filepath) if os.path.isdir(os.path.join(filepath, folder))]\n",
    "#     return folder_names\n",
    "\n",
    "# folder_names = get_folder_names(filepath)\n",
    "\n",
    "categories = ['cardboard', 'glass', 'metal', 'paper', 'plastic']\n",
    "labels = flatten_lst([[label] * 300 for label in categories])\n",
    "print(labels)\n",
    "# One-hot encoding of the labels\n",
    "encoder = OneHotEncoder(categories=[categories], sparse_output=False)\n",
    "y = encoder.fit_transform(np.array(labels).reshape(-1,1))\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "\n",
    "# CNN model\n",
    "inputs = Input(shape=(input_shape.values()))\n",
    "hidden = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu')(inputs)\n",
    "hidden = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu')(hidden)\n",
    "hidden = MaxPooling2D(pool_size=(2,2))(hidden)\n",
    "hidden = Dropout(rate=0.25)(hidden)\n",
    "hidden = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu')(hidden)\n",
    "hidden = MaxPooling2D(pool_size=(2,2))(hidden)\n",
    "hidden = Dropout(rate=0.25)(hidden)\n",
    "hidden = Flatten()(hidden)\n",
    "hidden = Dense(units=256, activation='relu')(hidden)\n",
    "hidden = Dropout(rate=0.25)(hidden)\n",
    "output = Dense(units=y.shape[-1], activation='softmax')(hidden)\n",
    "cnn = Model(inputs=inputs, outputs=output, name='CNN_CBP_Class')\n",
    "\n",
    "# Configuration of the training process\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "history = cnn.fit(x=aimages, y=y, epochs=epochs, batch_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(a):\n",
    "    a = np.asarray(a)\n",
    "    a = (a - a.min()) / (a.max() - a.min())\n",
    "    return a\n",
    "\n",
    "plt.plot(range(1, epochs+1), minmax(history.history['loss']))\n",
    "plt.plot(range(1, epochs+1), minmax(history.history['accuracy']))\n",
    "plt.title('Model learning curves')\n",
    "plt.xlabel('epochs')\n",
    "plt.gca().legend(('loss', 'accuracy'))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric functions\n",
    "def accuracy(actuals, preds):\n",
    "    actuals, preds = np.asarray(actuals), np.asarray(preds)\n",
    "    return np.mean(np.ravel(actuals) == np.ravel(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = cnn.predict(aimages)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "yhat = np.asarray(categories)[yhat]\n",
    "\n",
    "print(f'Accuracy: {round(accuracy(labels, yhat) * 100, 2)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Transfer learning is the reuse of an pre-trained neural network for similar, related tasks. An overview of pre-trained convolutional neural networks in Tensorflow can be found on https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Images should be in specified input shape for pre-trained model\n",
    "pt_input_shape = {'height': 224, 'width': 224, 'channels': 3}\n",
    "pt_images = images_to_array(read_images(image_names, height=pt_input_shape['height'], width=pt_input_shape['width']))\n",
    "\n",
    "# Load pre-configured and pre-trained CNN without top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=tuple(pt_input_shape.values()))\n",
    "# Mark loaded layers as not trainable (freeze layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Place new top layer on base model\n",
    "output = Flatten()(base_model.layers[-1].output)\n",
    "output = Dense(units=1024, activation='relu')(output)\n",
    "output = Dense(units=y.shape[-1], activation='softmax')(output)\n",
    "\n",
    "# Define the entire new model\n",
    "pt_cnn = Model(inputs=base_model.inputs, outputs=output)\n",
    "\n",
    "# Train the new model\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "pt_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "pt_history = pt_cnn.fit(x=pt_images, y=y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Predict on the model\n",
    "yhat = pt_cnn.predict(pt_images)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "yhat = np.asarray(categories)[yhat]\n",
    "print(f'Accuracy: {round(accuracy(labels, yhat) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way\n",
    "pt_cnn = tf.keras.Sequential()\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=tuple(pt_input_shape.values()), classes=y.shape[-1])\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pt_cnn.add(base_model)\n",
    "pt_cnn.add(Flatten())\n",
    "pt_cnn.add(Dense(units = 1024, activation='relu'))\n",
    "pt_cnn.add(Dense(units = y.shape[-1], activation='softmax'))\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "pt_cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "pt_history = pt_cnn.fit(x=pt_images, y=y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Predict on the model\n",
    "yhat = pt_cnn.predict(pt_images)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "yhat = np.asarray(categories)[yhat]\n",
    "print(f'Accuracy: {round(accuracy(labels, yhat) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pt_history.history['accuracy'])\n",
    "plt.axis(ymin=0.3, ymax = 1)\n",
    "plt.grid()\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuarcy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "acc = accuracy_score(labels, yhat)\n",
    "pre = precision_score(labels, yhat, average=None)\n",
    "rec = recall_score(labels, yhat, average=None)\n",
    "f1 = f1_score(labels, yhat, average=None)\n",
    "print(f'Accuracy: {acc}, Precision: {pre}, Recall: {rec}, F1-Score: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
